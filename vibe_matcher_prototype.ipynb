{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500fd721",
   "metadata": {},
   "source": [
    "# Vibe Matcher Prototype\n",
    "\n",
    "Dual TF-IDF / OpenAI embedding demo. Toggle USE_OPENAI at top of the script to switch embedding backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5308bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68de98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7608a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d06174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vibe Matcher Prototype (dual TF-IDF / OpenAI)\n",
    "Run: python vibe_matcher_prototype.py\n",
    "Requirements: scikit-learn, pandas, matplotlib. For OpenAI embeddings, install openai and set OPENAI_API_KEY env var.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional OpenAI\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except Exception:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "# --- Config ---\n",
    "USE_OPENAI = False  # Toggle: set True to use OpenAI embeddings (requires OPENAI_API_KEY)\n",
    "OPENAI_MODEL = \"text-embedding-ada-002\"\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')\n",
    "\n",
    "if OPENAI_AVAILABLE and OPENAI_API_KEY:\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# --- Sample data ---\n",
    "products = [\n",
    "    {\"name\": \"Boho Dress\", \"desc\": \"Flowy, earthy tones for festival vibes\"},\n",
    "    {\"name\": \"Denim Jacket\", \"desc\": \"Energetic urban chic, cropped with patch details\"},\n",
    "    {\"name\": \"Athleisure Set\", \"desc\": \"Comfort-first, sporty, energetic for gym-to-street\"},\n",
    "    {\"name\": \"Silk Slip\", \"desc\": \"Minimalist, elegant evening wear with satin sheen\"},\n",
    "    {\"name\": \"Corduroy Pants\", \"desc\": \"Warm, cozy textured pants perfect for autumn walks\"},\n",
    "    {\"name\": \"Street Sneaks\", \"desc\": \"Bold, high-top sneakers with urban attitude\"},\n",
    "    {\"name\": \"Linen Shirt\", \"desc\": \"Light, breezy, relaxed summer vibes â€” clean and natural\"},\n",
    "    {\"name\": \"Statement Blazer\", \"desc\": \"Sharp, energetic, structured blazer for confident looks\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# --- Embedding functions ---\n",
    "def embed_with_tfidf(texts: List[str], max_features: int = 256):\n",
    "    vec = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "    X = vec.fit_transform(texts).toarray()\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    norms[norms==0] = 1.0\n",
    "    X = X / norms\n",
    "    return X, vec\n",
    "\n",
    "def embed_with_openai(texts: List[str], model: str = OPENAI_MODEL):\n",
    "    if not OPENAI_AVAILABLE or not openai.api_key:\n",
    "        raise RuntimeError(\"OpenAI not available or API key not set\")\n",
    "    embeddings = []\n",
    "    batch = []\n",
    "    for t in texts:\n",
    "        batch.append(t)\n",
    "    # OpenAI supports batching; use single call\n",
    "    resp = openai.Embedding.create(model=model, input=batch)\n",
    "    for r in resp['data']:\n",
    "        embeddings.append(r['embedding'])\n",
    "    emb = np.array(embeddings)\n",
    "    norms = np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "    norms[norms==0] = 1.0\n",
    "    emb = emb / norms\n",
    "    return emb\n",
    "\n",
    "def get_embeddings(texts: List[str], prefer_openai: bool = USE_OPENAI):\n",
    "    if prefer_openai and OPENAI_AVAILABLE and openai.api_key:\n",
    "        try:\n",
    "            return embed_with_openai(texts)\n",
    "        except Exception as e:\n",
    "            print(\"OpenAI failed, falling back to TF-IDF:\", e)\n",
    "    emb, vec = embed_with_tfidf(texts)\n",
    "    return emb, vec\n",
    "\n",
    "# --- Build product embeddings ---\n",
    "if USE_OPENAI:\n",
    "    emb_matrix = None\n",
    "    try:\n",
    "        emb_matrix = embed_with_openai(df['desc'].tolist())\n",
    "        embedding_vectorizer = None\n",
    "    except Exception as ex:\n",
    "        print(\"OpenAI embedding failed, falling back to TF-IDF:\", ex)\n",
    "        emb_matrix, embedding_vectorizer = embed_with_tfidf(df['desc'].tolist())\n",
    "else:\n",
    "    emb_matrix, embedding_vectorizer = embed_with_tfidf(df['desc'].tolist())\n",
    "\n",
    "df['embedding'] = list(emb_matrix)\n",
    "\n",
    "# --- Similarity search ---\n",
    "def query_top_k(query: str, df: pd.DataFrame, k: int = 3, threshold: float = 0.35, prefer_openai: bool = USE_OPENAI):\n",
    "    # Get query embedding\n",
    "    if prefer_openai and OPENAI_AVAILABLE and openai.api_key:\n",
    "        q_emb = embed_with_openai([query])\n",
    "    else:\n",
    "        q_emb = embedding_vectorizer.transform([query]).toarray()\n",
    "        norms = np.linalg.norm(q_emb, axis=1, keepdims=True)\n",
    "        norms[norms==0] = 1.0\n",
    "        q_emb = q_emb / norms\n",
    "    # Ensure shapes align\n",
    "    X = np.vstack(df['embedding'].values)\n",
    "    if X.shape[1] != q_emb.shape[1]:\n",
    "        raise ValueError(f\"Embedding dimension mismatch: products {X.shape[1]} vs query {q_emb.shape[1]}\")\n",
    "    sims = cosine_similarity(q_emb, X)[0]\n",
    "    top_idx = np.argsort(sims)[::-1][:k]\n",
    "    results = df.iloc[top_idx].copy()\n",
    "    results['score'] = sims[top_idx]\n",
    "    fallback_msg = None if results['score'].iloc[0] >= threshold else \"No confident match found.\"\n",
    "    return results.reset_index(drop=True), fallback_msg\n",
    "\n",
    "# --- Tests / sample queries ---\n",
    "def run_queries(queries):\n",
    "    results = []\n",
    "    for q in queries:\n",
    "        t0 = time.perf_counter()\n",
    "        res, fb = query_top_k(q, df)\n",
    "        t1 = time.perf_counter()\n",
    "        print(f\"\\nQuery: {q}\")\n",
    "        print(res[['name', 'score']])\n",
    "        print(f\"Latency: {t1 - t0:.4f}s\")\n",
    "        if fb:\n",
    "            print(\"Fallback:\", fb)\n",
    "        results.append({\n",
    "            'query': q,\n",
    "            'top_score': float(res['score'].iloc[0]),\n",
    "            'latency': t1 - t0\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_queries = [\n",
    "        \"energetic urban chic\",\n",
    "        \"cozy autumn outfit\",\n",
    "        \"minimalist evening elegance\"\n",
    "    ]\n",
    "    results = run_queries(sample_queries)\n",
    "\n",
    "    # Simple metric\n",
    "    threshold = 0.35\n",
    "    good = sum(1 for r in results if r['top_score'] > threshold)\n",
    "    print(f\"\\nGood queries (top_score>{threshold}): {good}/{len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
